var documenterSearchIndex = {"docs":
[{"location":"api/#Gaussian-Process.jl","page":"API","title":"Gaussian Process.jl","text":"","category":"section"},{"location":"api/#Kernels","page":"API","title":"Kernels","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"GaussianProcess.exp_cov_fn \nGaussianProcess.sqexp_cov_fn","category":"page"},{"location":"api/#GaussianProcess.exp_cov_fn","page":"API","title":"GaussianProcess.exp_cov_fn","text":"exp_cov_fn(X; delta=0.0005, kwargs...)\n\nImplementation of the exponential kernel also known as Ornsteinâ€“Uhlenbeck.\n\nArguments:\n\nX::Vector{Float} : node's position vector \ndelta::Float : strength of white noise component for numerical stability. \neta::Number : covariance matrix amplitude.\nl::Number : covariance matrix correlation length.\n\nReturns:\n\ncov_mat::Matrix : GP's covariance matrix\n\nUsage:\n\nexp_cov_fn(x; eta=0.05, l=1.0)\n\n\n\n\n\n","category":"function"},{"location":"api/#GaussianProcess.sqexp_cov_fn","page":"API","title":"GaussianProcess.sqexp_cov_fn","text":"sqexp_cov_fn(X; delta=0.0005, kwargs...)\n\nImplementation of the square exponential kernel. \n\nArguments:\n\nX::Vector{Float} : node's position vector \ndelta::Float : strength of white noise component for numerical stability. \neta::Number : covariance matrix amplitude.\nl::Number : covariance matrix correlation length.\n\nReturns:\n\ncov_mat::Matrix : GP's covariance matrix\n\nUsage:\n\nsqexp_cov_fn(x; eta=0.05, l=1.0)\n\n\n\n\n\n","category":"function"},{"location":"api/#GP's","page":"API","title":"GP's","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"GaussianProcess.marginal_lkl\nGaussianProcess.latent_GP\nGaussianProcess.conditional\nGaussianProcess.posterior_predict","category":"page"},{"location":"api/#GaussianProcess.marginal_lkl","page":"API","title":"GaussianProcess.marginal_lkl","text":"marginal_lkl(mean, kernel; data_cov=nothing)\n\nMarginal likelihood implementation of a GP's.  This is equivalent to analytically marginalizing over the GP's nodes.  Used when GP is linearly related to data. \n\nArguments:\n\nmeam::Vector{Number}: GP's mean.\nkernel::Matrix{Number}: GP's covariance matrix\ndata_cov::Matrix{Float}: data covariance matrix\n\nReturns:\n\nGP::MvNormal: instance of MvNormal.\n\n\n\n\n\n","category":"function"},{"location":"api/#GaussianProcess.latent_GP","page":"API","title":"GaussianProcess.latent_GP","text":"latent_GP(mean, nodes, kernel)\n\nLatent variable implementation of a GP's.  Rotates the GP ndodes by the covariance  matrix and adds them to the mean vector.  Used when GP is not linearly related to data. \n\nArguments:\n\nmean::Vector{Number}: GP's mean.\nnodes::Vector{Number}: GP's nodes.\nkernel::Matrix{Number}: GP's cov mat.\n\nReturns:\n\nGP::Vector{Number}: Gaussian process realization.\n\n\n\n\n\n","category":"function"},{"location":"api/#GaussianProcess.conditional","page":"API","title":"GaussianProcess.conditional","text":"conditional(old_X, new_X, latent_gp, cov_fn; kwargs...)\n\nGiven the GP's covariance matrix, applies a  Wiener filter to transform the latent GP  N-dimensional parameter space to M-dimensional  target parameter space.\n\nArguments:\n\nold_X::Vector{Float}: position vector of the latent GP.\nnew_X::Vector{Float}: target position vector.\nlatent_gp::Vector{Number}: latent GP realization. \na=a, b=b... : Covariance matrix hyperparameters.\n\nReturns:\n\ngp::Vector{Number}: GP in target space. \n\n\n\n\n\n","category":"function"},{"location":"api/#GaussianProcess.posterior_predict","page":"API","title":"GaussianProcess.posterior_predict","text":"posterior_predict(X_new, X_old, mean_new, mean_old, data, cov_fn;\n                        data_cov=nothing)\n\nReturns a function that transforms the GP  from an old parameter space to a new parameter space,  given a particular set of values for the GP's covariance  matrix hyperparameters. \n\nArguments:\n\nnew_X::Vector{Float}: target position vector.\nold_X::Vector{Float}: position vector of the latent GP.\nnew_mean::Vector{Number}: expected GP mean for new position vector. \nold_mean::Vector{Number}: GP's mean in old position vector. \ndata::Vector{Float}: data vector.\ncov_fn::function: covariance function used to generate the GP's kernel. \ndata_cov::Matrix{Float}: data covariance matrix\n\nReturns:\n\npredict(): predicts GP in target space.  Arguments:\na=a, b=b...: Cov mat hyperparameters\nReturns:\nGP::MvNormal: instance of MvNormal.\n\n\n\n\n\n","category":"function"},{"location":"#GaussianProcess.jl","page":"Home","title":"GaussianProcess.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"A minimal Gaussian process package in Julia.","category":"page"}]
}
